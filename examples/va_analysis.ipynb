{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lightexperiments.light import Light\n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy as np\n",
    "import seaborn as sbn\n",
    "%matplotlib inline\n",
    "light = Light()\n",
    "light.launch()\n",
    "\n",
    "d = light.db.find({\"tags\": \"variational_autoencoder_example\"})\n",
    "documents = list(d)\n",
    "\n",
    "light.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc246e715d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEDCAYAAAAyZm/jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nESkZFb+ISMmo+EVESub/AXWWNnOMtf3qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc246e71610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "i = 0\n",
    "#print documents[0][\"loss_train\"][-1]\n",
    "sampled_documents = np.random.choice(documents, min(len(documents), 5), replace=False)\n",
    "sampled_documents = documents[0:1]\n",
    "for document in sampled_documents:\n",
    "    #if(document['loss_train'][-1] > 110):\n",
    "    #    continue\n",
    "    if np.nan in document['loss_train']:\n",
    "        continue\n",
    "    plt.plot(document['epoch'], document['loss_train'], label=\"z:{0},h:{1},lr:{2:.2f}\".format(document['z_dim'], \n",
    "                                                                                              document['hidden'],                                                                                              document['learning_rate']*10**3))\n",
    "    #print(document.keys())\n",
    "    plt.grid(True)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import matplotlib as mpl\n",
      "mpl.use('Agg')\n",
      "import numpy as np\n",
      "from lasagne.generative import va\n",
      "from lasagne.easy import (BatchOptimizer, LightweightModel,\n",
      "                          get_2d_square_image_view)\n",
      "from lasagne.layers.batch_norm import batch_norm\n",
      "from lasagne.misc.plot_weights import grid_plot\n",
      "from lasagne import layers, nonlinearities, updates, init\n",
      "from sklearn.datasets import load_digits\n",
      "from lasagne.datasets.mnist import MNIST\n",
      "from lasagne.datasets.faces import Faces\n",
      "import theano\n",
      "from sklearn.utils import shuffle\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "import theano\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from theano.sandbox import rng_mrg\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from lightexperiments.light import Light\n",
      "    light = Light()\n",
      "    light.launch() # init the DB\n",
      "    light.initials() # save the date and init the timer\n",
      "\n",
      "    light.file_snapshot() # save the content of the python file running\n",
      "    state = 1515\n",
      "    #np.random.seed(state)\n",
      "    #light.set_seed(state) # save the content of the seed\n",
      "\n",
      "    light.tag(\"variational_autoencoder_example\")\n",
      "\n",
      "    z_dim = np.random.choice((2, 5, 10, 20, 30, 80, 100, 120, 160, 180))\n",
      "    hidden = np.random.randint(10, 1200)\n",
      "    max_epochs = np.random.randint(50, 500)\n",
      "    learning_rate = 10**np.random.uniform(-6, -3)\n",
      "    batch_size = np.random.choice((10, 50, 100, 128, 164, 200, 256, 300, 500, 512))\n",
      "\n",
      "    \n",
      "    #z_dim = np.random.randint(2, 200)\n",
      "    #hidden = np.random.randint(50, 700)\n",
      "    #max_epochs = 150\n",
      "    #learning_rate = 10**np.random.uniform(-5, -2)\n",
      "    #batch_size = 256\n",
      "\n",
      "    #z_dim = 180\n",
      "    #hidden = 601\n",
      "    #learning_rate = 0.000296\n",
      "    #max_epochs = 150\n",
      "    #batch_size = 256\n",
      "    batch_normalization = False\n",
      "\n",
      "\n",
      "    light.set(\"z_dim\", z_dim)\n",
      "    light.set(\"hidden\", hidden)\n",
      "    light.set(\"max_epochs\", max_epochs)\n",
      "    light.set(\"learning_rate\", learning_rate)\n",
      "    light.set(\"batch_size\", batch_size)\n",
      "    light.set(\"batch_normalization\", batch_normalization)\n",
      "\n",
      "    data = MNIST(which='train')\n",
      "    #data = Faces(dataset='faces94')\n",
      "    data.load()\n",
      "    X = data.X\n",
      "    #y = data.y\n",
      "    #X = 1.*(np.random.uniform(size=X.shape) <= X)\n",
      "\n",
      "    #data = load_digits()\n",
      "    #print(data.keys())\n",
      "    #X = data['data']\n",
      "    #y = data['target']\n",
      "\n",
      "    X = X.astype(theano.config.floatX)\n",
      "    y = data.y if hasattr(data, \"y\") else None\n",
      "    #y = y[0:n]\n",
      "\n",
      "    if y is not None:\n",
      "        X, y = shuffle(X, y)\n",
      "    else:\n",
      "        X = shuffle(X)\n",
      "    #X, y = shuffle(X, y)\n",
      "    #X, y = shuffle(X, y, random_state=state)\n",
      "\n",
      "    # X to Z (decoder)\n",
      "    x_in = layers.InputLayer(shape=(None, X.shape[1]))\n",
      "    #h = layers.DropoutLayer(x_in, p=0.3)\n",
      "    h = layers.DenseLayer(x_in, num_units=hidden,\n",
      "                          #W=init.Uniform(-0.001, 0.001),\n",
      "                          nonlinearity=nonlinearities.rectify)\n",
      "    h_encoder = h\n",
      "    h = batch_norm(h)\n",
      "    #h = layers.DropoutLayer(h, p=0.5)\n",
      "    h = layers.DenseLayer(h, num_units=hidden,\n",
      "                          #W=init.Uniform(-0.001, 0.001),\n",
      "                          nonlinearity=nonlinearities.rectify)\n",
      "    h = batch_norm(h)\n",
      "    #h = layers.DropoutLayer(h, p=0.5)\n",
      "    #h = layers.DropoutLayer(h, p=0.5)\n",
      "\n",
      "    #h = layers.DenseLayer(h, num_units=hidden/4,\n",
      "    #                      #W=init.Uniform(-0.001, 0.001),\n",
      "    #                      nonlinearity=nonlinearities.rectify)\n",
      "    #h = batch_norm(h)\n",
      "    #h = layers.DropoutLayer(h, p=0.5)\n",
      "\n",
      "    z_mean_out = layers.DenseLayer(h, num_units=z_dim,\n",
      "                                   #W=init.Uniform(-0.001, 0.001),\n",
      "                                   nonlinearity=nonlinearities.linear)\n",
      "    z_sigma_out = layers.DenseLayer(h, num_units=z_dim,\n",
      "                                    #W=init.Uniform(-0.001, 0.001),\n",
      "                                    nonlinearity=nonlinearities.linear)\n",
      "\n",
      "    nnet_x_to_z = LightweightModel([x_in],\n",
      "                                   [z_mean_out, z_sigma_out])\n",
      "    # Z to X (encoder)\n",
      "    z_in = layers.InputLayer(shape=(None, z_dim))\n",
      "    h = layers.DenseLayer(z_in, num_units=hidden/4,\n",
      "                          #W=init.Uniform(-0.001, 0.001),\n",
      "                          nonlinearity=nonlinearities.rectify)\n",
      "\n",
      "    h_decoder = h\n",
      "    #h = batch_norm(h)\n",
      "    h = layers.DenseLayer(h, num_units=hidden,\n",
      "#                          W=init.Uniform(-0.001, 0.001),\n",
      "                          nonlinearity=nonlinearities.rectify)\n",
      "\n",
      "    #h = batch_norm(h)\n",
      "    #h = layers.DenseLayer(h, num_units=hidden,\n",
      "    #                      #W=init.Uniform(-0.001, 0.001),\n",
      "     #                     nonlinearity=nonlinearities.rectify)\n",
      "\n",
      "    h = batch_norm(h)\n",
      "    x_out = layers.DenseLayer(h, num_units=X.shape[1],\n",
      "                              #W=init.Uniform(-0.001, 0.001),\n",
      "                              nonlinearity=nonlinearities.linear)\n",
      "    nnet_z_to_x = LightweightModel([z_in], [x_out])\n",
      "\n",
      "    # instantiate the model\n",
      "    class MyBatchOptimizer(BatchOptimizer):\n",
      "\n",
      "        def iter_update(self, epoch, nb_batches, iter_update_batch):\n",
      "\n",
      "            super(MyBatchOptimizer, self).iter_update(epoch, nb_batches, iter_update_batch)\n",
      "            #print(\"h1\", (h1.W.get_value()**2).sum())\n",
      "            #print(\"h2\", (h2.W.get_value()**2).sum())\n",
      "            #print(\"z_mean\", (z_mean_out.W.get_value()**2).sum())\n",
      "            #print(\"z_sigma\", (z_sigma_out.W.get_value()**2).sum())\n",
      "            #print(\"x_out\", (x_out.W.get_value()**2).sum())\n",
      "\n",
      "            #assert not np.isnan(np.sum(h1.W.get_value())), \"h1 has nan\"\n",
      "            #assert not np.isnan(np.sum(h2.W.get_value())), \"h2 has nan\"\n",
      "            #assert not np.isnan(np.sum(h.W.get_value())), \"h has nan\"\n",
      "            #assert not np.isnan(np.sum(z_mean_out.W.get_value())), \"z_mean_out has nan\"\n",
      "            #assert not np.isnan(np.sum(z_sigma_out.W.get_value())), \"z_sigma_out has nan\"\n",
      "            #assert not np.isnan(np.sum(x_out.W.get_value())), \"x_out has nan\"\n",
      "            #self.stats[-1][\"reconstruction_error\"] = model.reconstruction_error_function(X)\n",
      "            #self.stats[-1][\"log_likelihood\"] = model.log_likelihood_approximation_function(X)\n",
      "            for k, v in self.stats[-1].items():\n",
      "                light.append(k, float(v))\n",
      "            light.append(\"W_encoder_mean\", float(h_encoder.W.get_value().mean()))\n",
      "            light.append(\"W_encoder_std\", float(h_encoder.W.get_value().std()))\n",
      "            light.append(\"W_decoder_mean\", float(h_encoder.W.get_value().mean()))\n",
      "            light.append(\"W_decoder_std\", float(h_decoder.W.get_value().std()))\n",
      "\n",
      "            #nb = 20\n",
      "            #z_mean, z_sigma = model.encode(X[0:nb])\n",
      "            #if epoch % 50 == 0:\n",
      "            #    light.append(\"activations\", z_mean.tolist())\n",
      "            #    light.append(\"activations_sigma\", z_sigma.tolist())\n",
      "            #    #light.append(\"W_encoder\", h_encoder.W.get_value().tolist())\n",
      "            #    #light.append(\"W_decoder\", h_decoder.W.get_value().tolist())\n",
      "\n",
      "    batch_optimizer = MyBatchOptimizer(max_nb_epochs=max_epochs,\n",
      "                                       optimization_procedure=(updates.rmsprop, {\"learning_rate\": learning_rate}),\n",
      "                                       verbose=1,\n",
      "                                       whole_dataset_in_device=True,\n",
      "                                       batch_size=batch_size)\n",
      "    model = va.VariationalAutoencoder(nnet_x_to_z, nnet_z_to_x, \n",
      "                                  batch_optimizer, \n",
      "                                  rng=rng_mrg.MRG_RandomStreams(),\n",
      "                                  nb_z_samples=1)\n",
      "    model.fit(X)\n",
      "\n",
      "\n",
      "    X_ = model.sample(200, only_means=True)\n",
      "    if hasattr(data, \"img_dim\"):\n",
      "        X_  = X_.reshape(  [X_.shape[0]]  + list(data.img_dim) )\n",
      "    else:\n",
      "        X_ = get_2d_square_image_view(X_)\n",
      "    grid_plot(X_, imshow_options={\"cmap\": \"gray\", \"interpolation\": None})\n",
      "    plt.savefig('out-samples.png')\n",
      "    #light.set(\"out-samples.png\", open(\"out-samples.png\").read())\n",
      "    plt.clf()\n",
      "    features = h_encoder.W.get_value().T\n",
      "    if hasattr(data, \"img_dim\"):\n",
      "        features = features.reshape(   [features.shape[0]] + list(data.img_dim) )\n",
      "    else:\n",
      "        features = get_2d_square_image_view(features)\n",
      "    grid_plot(features, imshow_options={\"cmap\": \"gray\"})\n",
      "    plt.savefig('out-encoder-features.png')\n",
      "    #light.set(\"out-encoder-features.png\", open(\"out-encoder-features.png\").read())\n",
      "\n",
      "    plt.clf()\n",
      "\n",
      "    features = x_out.W.get_value()\n",
      "    if hasattr(data, \"img_dim\"):\n",
      "        features = features.reshape(   [features.shape[0]] + list(data.img_dim) )\n",
      "    else:\n",
      "        features = get_2d_square_image_view(features)\n",
      "    grid_plot(features, imshow_options={\"cmap\": \"gray\"})\n",
      "    plt.show()\n",
      "    plt.savefig('out-decoder-features.png')\n",
      "    #light.set(\"out-decoder-features.png\", open(\"out-decoder-features.png\").read())\n",
      "    plt.clf()\n",
      "\n",
      "\n",
      "    iterations = (range(len(batch_optimizer.stats)))\n",
      "    values = np.array([stats[\"loss_train\"] for stats in batch_optimizer.stats])\n",
      "    errors = np.array([stats[\"loss_std\"] for stats in batch_optimizer.stats])\n",
      "    #log_likelihood = np.array([stats[\"log_likelihood\"] for stats in batch_optimizer.stats])\n",
      "\n",
      "    plt.errorbar(iterations, values, yerr=errors)\n",
      "    #plt.plot(iterations, log_likelihood)\n",
      "    plt.show()\n",
      "    plt.savefig(\"out-loss-per-epoch.png\")\n",
      "\n",
      "    plt.clf()\n",
      "\n",
      "    from sklearn.decomposition import PCA\n",
      "    code, code_sigma = model.encode(X)\n",
      "    pca = PCA(n_components=2)\n",
      "    code_2d = pca.fit_transform(code)\n",
      "    if y is None:\n",
      "        plt.scatter(code_2d[:, 0], code_2d[:, 1])\n",
      "    else:\n",
      "        plt.scatter(code_2d[:, 0], code_2d[:, 1], c=y)\n",
      "    plt.show()\n",
      "    plt.savefig(\"out-embedding.png\")\n",
      "    #light.set(\"out-embedding.png\", open(\"out-embedding.png\").read())\n",
      "\n",
      "    \"\"\"\n",
      "    clf = RandomForestClassifier(n_estimators=50)\n",
      "    code, code_log_sigma = model.encode(X)\n",
      "    code_con = np.concatenate((code, code_log_sigma), axis=1)\n",
      "    clf.fit(code_con, y)\n",
      "\n",
      "    data = MNIST(which='test')\n",
      "    data.load()\n",
      "    X_test = data.X\n",
      "    y_test = data.y\n",
      "\n",
      "    code, code_log_sigma = model.encode(X_test)\n",
      "    code_con = np.concatenate((code, code_log_sigma), axis=1)\n",
      "    print(accuracy_score(clf.predict(code_con), y_test))\n",
      "    \"\"\"\n",
      "    \n",
      "    light.endings() # save the duration\n",
      "    light.store_experiment() # update the DB\n",
      "    light.close() # close the DB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(documents[0][\"code_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z_dim</th>\n",
       "      <th>hidden</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss_train_final</th>\n",
       "      <th>duration</th>\n",
       "      <th>max_epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>batch_normalization</th>\n",
       "      <th>sec/epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>180</td>\n",
       "      <td>990</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>93.557022</td>\n",
       "      <td>359.342853</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>359.342853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>980</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>94.217857</td>\n",
       "      <td>1444.650298</td>\n",
       "      <td>408</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>1444.650298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>1045</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>94.285980</td>\n",
       "      <td>1473.040571</td>\n",
       "      <td>242</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>1473.040571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160</td>\n",
       "      <td>1031</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>94.308983</td>\n",
       "      <td>1075.523649</td>\n",
       "      <td>179</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>1075.523649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>160</td>\n",
       "      <td>838</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>95.055443</td>\n",
       "      <td>367.404968</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>367.404968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30</td>\n",
       "      <td>434</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>95.281204</td>\n",
       "      <td>937.973756</td>\n",
       "      <td>466</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>937.973756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>20</td>\n",
       "      <td>591</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>95.774971</td>\n",
       "      <td>188.015571</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>188.015571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>80</td>\n",
       "      <td>596</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>96.433929</td>\n",
       "      <td>943.193688</td>\n",
       "      <td>362</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>943.193688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>120</td>\n",
       "      <td>755</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>96.672455</td>\n",
       "      <td>292.512025</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>292.512025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>80</td>\n",
       "      <td>681</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>96.820915</td>\n",
       "      <td>482.243987</td>\n",
       "      <td>92</td>\n",
       "      <td>200</td>\n",
       "      <td>True</td>\n",
       "      <td>482.243987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>30</td>\n",
       "      <td>449</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>96.910507</td>\n",
       "      <td>264.262018</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>264.262018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>10</td>\n",
       "      <td>720</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>97.070831</td>\n",
       "      <td>291.680071</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>291.680071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>20</td>\n",
       "      <td>542</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>97.568420</td>\n",
       "      <td>201.336570</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>201.336570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>10</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>98.300133</td>\n",
       "      <td>456.392686</td>\n",
       "      <td>450</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>456.392686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>98.457680</td>\n",
       "      <td>594.320015</td>\n",
       "      <td>369</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>594.320015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>80</td>\n",
       "      <td>422</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>98.896469</td>\n",
       "      <td>282.408539</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>282.408539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>594</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>99.074944</td>\n",
       "      <td>1018.563063</td>\n",
       "      <td>287</td>\n",
       "      <td>164</td>\n",
       "      <td>False</td>\n",
       "      <td>1018.563063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>80</td>\n",
       "      <td>777</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>99.438187</td>\n",
       "      <td>366.459323</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>366.459323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>120</td>\n",
       "      <td>981</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>100.093483</td>\n",
       "      <td>430.945189</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>430.945189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>100</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>100.351868</td>\n",
       "      <td>315.163000</td>\n",
       "      <td>450</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>315.163000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>160</td>\n",
       "      <td>621</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>100.408752</td>\n",
       "      <td>164.821176</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>164.821176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>20</td>\n",
       "      <td>757</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>100.853874</td>\n",
       "      <td>206.325678</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>206.325678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>100</td>\n",
       "      <td>743</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>100.909172</td>\n",
       "      <td>168.354217</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>168.354217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>180</td>\n",
       "      <td>651</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>100.910881</td>\n",
       "      <td>292.914595</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>292.914595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>10</td>\n",
       "      <td>980</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>101.061081</td>\n",
       "      <td>328.065847</td>\n",
       "      <td>450</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>328.065847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30</td>\n",
       "      <td>818</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>101.353409</td>\n",
       "      <td>1277.055206</td>\n",
       "      <td>422</td>\n",
       "      <td>512</td>\n",
       "      <td>True</td>\n",
       "      <td>1277.055206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>20</td>\n",
       "      <td>530</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>101.797844</td>\n",
       "      <td>358.221782</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>358.221782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>180</td>\n",
       "      <td>299</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>101.844330</td>\n",
       "      <td>635.902567</td>\n",
       "      <td>243</td>\n",
       "      <td>164</td>\n",
       "      <td>True</td>\n",
       "      <td>635.902567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>331</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>102.126747</td>\n",
       "      <td>740.496599</td>\n",
       "      <td>129</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>740.496599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>10</td>\n",
       "      <td>730</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>102.166489</td>\n",
       "      <td>228.217944</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>228.217944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>102.585030</td>\n",
       "      <td>208.081315</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>208.081315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>20</td>\n",
       "      <td>343</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>102.671577</td>\n",
       "      <td>215.092825</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>215.092825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>10</td>\n",
       "      <td>887</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>102.906715</td>\n",
       "      <td>480.397312</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>480.397312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>10</td>\n",
       "      <td>250</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>103.046120</td>\n",
       "      <td>235.051414</td>\n",
       "      <td>300</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>235.051414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>180</td>\n",
       "      <td>181</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>103.346321</td>\n",
       "      <td>290.288305</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>290.288305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>20</td>\n",
       "      <td>739</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>103.427673</td>\n",
       "      <td>203.014331</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>203.014331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>180</td>\n",
       "      <td>738</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>103.500786</td>\n",
       "      <td>487.544554</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>487.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>120</td>\n",
       "      <td>281</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>105.018486</td>\n",
       "      <td>260.604883</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>260.604883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>10</td>\n",
       "      <td>533</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>105.468048</td>\n",
       "      <td>204.048817</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>204.048817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>5</td>\n",
       "      <td>546</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>105.503403</td>\n",
       "      <td>198.164303</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>198.164303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>10</td>\n",
       "      <td>250</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>105.762032</td>\n",
       "      <td>237.059534</td>\n",
       "      <td>300</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>237.059534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>10</td>\n",
       "      <td>181</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>106.070366</td>\n",
       "      <td>162.542447</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>162.542447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>10</td>\n",
       "      <td>980</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>106.164017</td>\n",
       "      <td>1056.518149</td>\n",
       "      <td>450</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>1056.518149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>257</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>106.383858</td>\n",
       "      <td>255.945341</td>\n",
       "      <td>54</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>255.945341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>10</td>\n",
       "      <td>980</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>106.483002</td>\n",
       "      <td>216.530054</td>\n",
       "      <td>450</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>216.530054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>10</td>\n",
       "      <td>980</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>106.572845</td>\n",
       "      <td>1056.012146</td>\n",
       "      <td>450</td>\n",
       "      <td>512</td>\n",
       "      <td>False</td>\n",
       "      <td>1056.012146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>80</td>\n",
       "      <td>247</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>107.053177</td>\n",
       "      <td>414.485212</td>\n",
       "      <td>166</td>\n",
       "      <td>200</td>\n",
       "      <td>True</td>\n",
       "      <td>414.485212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>10</td>\n",
       "      <td>250</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>107.587830</td>\n",
       "      <td>128.995694</td>\n",
       "      <td>300</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>128.995694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>5</td>\n",
       "      <td>971</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>107.754242</td>\n",
       "      <td>255.551000</td>\n",
       "      <td>300</td>\n",
       "      <td>256</td>\n",
       "      <td>False</td>\n",
       "      <td>255.551000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>1039</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>109.527962</td>\n",
       "      <td>1856.670054</td>\n",
       "      <td>435</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>1856.670054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     z_dim  hidden  learning_rate  loss_train_final     duration  max_epochs  \\\n",
       "168    180     990       0.000210         93.557022   359.342853         300   \n",
       "0       10     980       0.000112         94.217857  1444.650298         408   \n",
       "5      100    1045       0.000234         94.285980  1473.040571         242   \n",
       "3      160    1031       0.000441         94.308983  1075.523649         179   \n",
       "129    160     838       0.000304         95.055443   367.404968         300   \n",
       "9       30     434       0.000488         95.281204   937.973756         466   \n",
       "162     20     591       0.000520         95.774971   188.015571         300   \n",
       "25      80     596       0.000149         96.433929   943.193688         362   \n",
       "131    120     755       0.000896         96.672455   292.512025         300   \n",
       "12      80     681       0.000932         96.820915   482.243987          92   \n",
       "163     30     449       0.000289         96.910507   264.262018         300   \n",
       "156     10     720       0.000209         97.070831   291.680071         300   \n",
       "174     20     542       0.000548         97.568420   201.336570         300   \n",
       "149     10    1500       0.000112         98.300133   456.392686         450   \n",
       "6      120     236       0.000612         98.457680   594.320015         369   \n",
       "143     80     422       0.000231         98.896469   282.408539         300   \n",
       "7      100     594       0.000057         99.074944  1018.563063         287   \n",
       "128     80     777       0.000075         99.438187   366.459323         300   \n",
       "133    120     981       0.000053        100.093483   430.945189         300   \n",
       "150    100    1500       0.000112        100.351868   315.163000         450   \n",
       "160    160     621       0.000922        100.408752   164.821176         300   \n",
       "145     20     757       0.000273        100.853874   206.325678         300   \n",
       "157    100     743       0.000222        100.909172   168.354217         300   \n",
       "173    180     651       0.000100        100.910881   292.914595         300   \n",
       "148     10     980       0.000112        101.061081   328.065847         450   \n",
       "17      30     818       0.000018        101.353409  1277.055206         422   \n",
       "154     20     530       0.000054        101.797844   358.221782         300   \n",
       "16     180     299       0.000085        101.844330   635.902567         243   \n",
       "19      20     331       0.000682        102.126747   740.496599         129   \n",
       "171     10     730       0.000225        102.166489   228.217944         300   \n",
       "130     30     300       0.000588        102.585030   208.081315         300   \n",
       "165     20     343       0.000107        102.671577   215.092825         300   \n",
       "146     10     887       0.000030        102.906715   480.397312         300   \n",
       "112     10     250       0.000331        103.046120   235.051414         300   \n",
       "164    180     181       0.000182        103.346321   290.288305         300   \n",
       "158     20     739       0.000071        103.427673   203.014331         300   \n",
       "166    180     738       0.000032        103.500786   487.544554         300   \n",
       "172    120     281       0.000067        105.018486   260.604883         300   \n",
       "137     10     533       0.000166        105.468048   204.048817         300   \n",
       "155      5     546       0.000775        105.503403   198.164303         300   \n",
       "109     10     250       0.000233        105.762032   237.059534         300   \n",
       "170     10     181       0.000257        106.070366   162.542447         300   \n",
       "153     10     980       0.000112        106.164017  1056.518149         450   \n",
       "11      10     257       0.000314        106.383858   255.945341          54   \n",
       "151     10     980       0.000112        106.483002   216.530054         450   \n",
       "152     10     980       0.000112        106.572845  1056.012146         450   \n",
       "22      80     247       0.000052        107.053177   414.485212         166   \n",
       "111     10     250       0.000506        107.587830   128.995694         300   \n",
       "167      5     971       0.000349        107.754242   255.551000         300   \n",
       "23       5    1039       0.000019        109.527962  1856.670054         435   \n",
       "\n",
       "     batch_size batch_normalization    sec/epoch  \n",
       "168         256               False   359.342853  \n",
       "0           512               False  1444.650298  \n",
       "5           128               False  1473.040571  \n",
       "3           200               False  1075.523649  \n",
       "129         256               False   367.404968  \n",
       "9           500                True   937.973756  \n",
       "162         256               False   188.015571  \n",
       "25          500                True   943.193688  \n",
       "131         256               False   292.512025  \n",
       "12          200                True   482.243987  \n",
       "163         256               False   264.262018  \n",
       "156         256               False   291.680071  \n",
       "174         256               False   201.336570  \n",
       "149         512               False   456.392686  \n",
       "6           512               False   594.320015  \n",
       "143         256               False   282.408539  \n",
       "7           164               False  1018.563063  \n",
       "128         256               False   366.459323  \n",
       "133         256               False   430.945189  \n",
       "150         512               False   315.163000  \n",
       "160         256               False   164.821176  \n",
       "145         256               False   206.325678  \n",
       "157         256               False   168.354217  \n",
       "173         256               False   292.914595  \n",
       "148         512               False   328.065847  \n",
       "17          512                True  1277.055206  \n",
       "154         256               False   358.221782  \n",
       "16          164                True   635.902567  \n",
       "19           50                True   740.496599  \n",
       "171         256               False   228.217944  \n",
       "130         256               False   208.081315  \n",
       "165         256               False   215.092825  \n",
       "146         256               False   480.397312  \n",
       "112         128               False   235.051414  \n",
       "164         256               False   290.288305  \n",
       "158         256               False   203.014331  \n",
       "166         256               False   487.544554  \n",
       "172         256               False   260.604883  \n",
       "137         256               False   204.048817  \n",
       "155         256               False   198.164303  \n",
       "109         128               False   237.059534  \n",
       "170         256               False   162.542447  \n",
       "153         512               False  1056.518149  \n",
       "11          100                True   255.945341  \n",
       "151         512               False   216.530054  \n",
       "152         512               False  1056.012146  \n",
       "22          200                True   414.485212  \n",
       "111         128               False   128.995694  \n",
       "167         256               False   255.551000  \n",
       "23          256                True  1856.670054  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cols_names = [  'z_dim', 'hidden', 'learning_rate', 'loss_train_final', 'duration', \n",
    "        'max_epochs', 'batch_size',\n",
    "        'batch_normalization',\n",
    "        'sec/epoch']\n",
    "cols_values = [\n",
    "    'z_dim', 'hidden', 'learning_rate', lambda d:d[\"loss_train\"][-1], 'duration', \n",
    "    'max_epochs', 'batch_size',\n",
    "    'batch_normalization',\n",
    "    'duration',\n",
    "    lambda d:(d['duration']/(d['max_epochs']))\n",
    "]\n",
    "    \n",
    "df = pd.DataFrame(columns=cols_names)\n",
    "for name, col in zip(cols_names, cols_values):\n",
    "    if type(col) == str:\n",
    "        df[name] = [d[col] for d in documents]\n",
    "    elif callable(col):\n",
    "        df[name] = [col(d) for d in documents]\n",
    "        \n",
    "df = df.sort('loss_train_final')\n",
    "df[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_dim                           10\n",
      "hidden                         980\n",
      "learning_rate          0.000112147\n",
      "loss_train_final          94.21786\n",
      "duration                   1444.65\n",
      "max_epochs                     408\n",
      "batch_size                     512\n",
      "batch_normalization          False\n",
      "sec/epoch                  3.54081\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd051b27a10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEDCAYAAAA4FgP0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd051ba08d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare batch normalization vs no batch normalization\n",
    "documents_ = [doc for doc in documents if \"hyperparamer_optimization_for_zdim_2\" in doc[\"tags\"]]\n",
    "plt.clf()\n",
    "doc_with_batch_norm = [doc for doc in documents_ if doc.get(\"batch_normalization\", False) is True]\n",
    "doc_without_batch_norm = [doc for doc in documents_ if doc.get(\"batch_normalization\", False) is False]\n",
    "\n",
    "nb_samples = 10\n",
    "doc_without_batch_norm = sorted(doc_without_batch_norm, key=lambda d:d[\"loss_train\"][-1])\n",
    "doc_without_batch_norm = doc_without_batch_norm[0:nb_samples]\n",
    "    \n",
    "doc_with_batch_norm = sorted(doc_with_batch_norm, key=lambda d:d[\"loss_train\"][-1])\n",
    "doc_with_batch_norm = doc_with_batch_norm[0:nb_samples]\n",
    "\n",
    "#for d in doc_with_batch_norm:\n",
    "\n",
    "plt.scatter([1]*len(doc_with_batch_norm), [d['loss_train'][-1] for d in doc_with_batch_norm], c='red', label='with_batch_norm')\n",
    "plt.scatter([1]*len(doc_without_batch_norm), [d['loss_train'][-1] for d in doc_without_batch_norm], c='blue', label='without_batch_norm')\n",
    "\n",
    "#plt.scatter(d['epoch'], d['loss_train'], label=\"with_batch_norm\", linewidth=2,c='red', alpha=0.5)\n",
    "#for d in doc_without_batch_norm:\n",
    "#    plt.plot(d['epoch'], d['loss_train'], label=\"without_batch_norm\", linewidth=2, c='blue', alpha=0.5)\n",
    "    \n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fd051ba0d90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAETCAYAAADd6corAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGVAwBrOgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd051bbd650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# influence of batch size on learning\n",
    "df_ = df.sort(\"batch_size\")\n",
    "plt.plot(df_[\"batch_size\"], (df_[\"sec/epoch\"]))\n",
    "plt.xlim(xmin=10, xmax=800)\n",
    "plt.xlabel('batch_size')\n",
    "plt.ylabel('sec/epoch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
